{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrMoAhKRhiYSqhSJ4lNn0r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nell87/drivendata_richter/blob/main/script/feature_selection_and_feature_engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing data** "
      ],
      "metadata": {
        "id": "fHOCjTo5NgkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "####    INCLUDES  _______________________________________ #### \n",
        "#Loading Libraries:# \n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "####    READING TRAIN AND TEST DATA _______________________________________ #### \n",
        "train_values = data = pd.read_csv(\"https://raw.githubusercontent.com/Nell87/drivendata_richter/main/data/train_values.csv\")\n",
        "train_labels = pd.read_csv(\"https://raw.githubusercontent.com/Nell87/drivendata_richter/main/data/train_labels.csv\")\n",
        "test_values = pd.read_csv(\"https://raw.githubusercontent.com/Nell87/drivendata_richter/main/data/test_values.csv\")\n",
        "train_merge = train_values.merge(train_labels, on = 'building_id', how = 'inner',)\n",
        "print(train_merge.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSaYfO6KNmIF",
        "outputId": "dde7b8f7-469b-460d-d96f-595f562004c9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(260601, 40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature engineering** "
      ],
      "metadata": {
        "id": "1HEXHmNRMZ7z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Feature engineering*: Location features**\n",
        "The features **geo_level_1_id, geo_level_2_id, geo_level_3_id** represent the geographic region in which building exists, from largest (level 1) to most specific sub-region (level 3). Possible values: level 1: 0-30, level 2: 0-1427, level 3: 0-12567.\n",
        "\n",
        "For every location feature there is a high number of categorical values, so we'll apply feature engineering on them. We'll replace every value with their conditional probabilities respect to every damage_grade category"
      ],
      "metadata": {
        "id": "cPmWL7FAMlpR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPkD2r9mKj0V"
      },
      "outputs": [],
      "source": [
        "# Function to replace a categorical feature with many values, with their conditional probabilities respecto to the predicted feature\n",
        "def categoricalvalues_condprob(data, index, columns, new_column_name):\n",
        "  # Create prob table\n",
        "  probs = data.groupby(index).size().div(len(data))\n",
        "  probs_group = data.groupby([index, columns]).size().div(len(data)).div(probs, axis=0, level=index).reset_index()\n",
        "  probs_group.columns= [index, columns, new_column_name]\n",
        "  probs_group_wide = probs_group.pivot(index=[index], columns = columns,values = new_column_name) #Reshape from long to wide\n",
        "  probs_group_wide = probs_group_wide.reset_index()\n",
        " \n",
        " # Rename columns\n",
        "  unique_values = np.unique(data.columns)\n",
        "  unique_values = len(unique_values) \n",
        "  for i in range(unique_values):\n",
        "    probs_group_wide.rename(columns={probs_group_wide.columns[-1]: 'test'}, inplace = True)\n",
        "\n",
        "\n",
        "\n",
        "  # Add column to main dataset\n",
        "  data_merge = data.merge(probs_group_wide, on=index, how='left')\n",
        "\n",
        "  # Get rid of the categorical feature\n",
        "  data_merge = data_merge.drop(index, axis=1)\n",
        "\n",
        "  # Return dataset\n",
        "  return probs_group_wide\n",
        "\n",
        "# Apply the function\n",
        "train_merge2 = categoricalvalues_condprob(train_merge, 'geo_level_1_id', 'damage_grade', 'prob_cond_geo_level_1')\n",
        "#train_merge = categoricalvalues_condprob(train_merge, 'geo_level_2_id', 'damage_grade', 'prob_cond_geo_level_2')\n",
        "#train_merge = categoricalvalues_condprob(train_merge, 'geo_level_3_id', 'damage_grade', 'prob_cond_geo_level_3')\n",
        "\n",
        "train_merge2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature selection** "
      ],
      "metadata": {
        "id": "KkWsRQdmMe8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_values = np.unique(train_merge.damage_grade)\n",
        "unique_values = len(unique_values) \n",
        "range(unique_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjYeXe0RMmhL",
        "outputId": "3b9c2fb7-6723-40cb-a5a3-5e5dccbcc15f"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    }
  ]
}